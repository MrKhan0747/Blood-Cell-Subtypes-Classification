{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Blood cell subtype classification\n",
    "import pandas as pd\n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TRAIN AND TEST DATASET ADDRESS\n",
    "DATASET=\"./dataset2-master/images/TRAIN\"\n",
    "TEST_DATASET=\"./dataset2-master/images/TEST\"\n",
    "\n",
    "#Categroized images\n",
    "#4 types of subcells\n",
    "CATEGORIES=[\"EOSINOPHIL\",\"LYMPHOCYTE\",\"MONOCYTE\",\"NEUTROPHIL\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reading original image from directory\n",
    "for category in CATEGORIES:\n",
    "        label=CATEGORIES.index(category)\n",
    "        path=os.path.join(DATASET,category)\n",
    "        \n",
    "        for img_file in os.listdir(path):\n",
    "            \n",
    "            # 1 indicates read image in RGB scale\n",
    "            # 0 indicates read image in grey scale\n",
    "            \n",
    "            img=cv.imread(os.path.join(path,img_file),1)\n",
    "            \n",
    "            #open cv read image in BGR format \n",
    "            #below we convert it to RGB format\n",
    "            img=cv.cvtColor(img,cv.COLOR_BGR2RGB)\n",
    "            #print(img.shape)\n",
    "            plt.imshow(img)\n",
    "            plt.show()\n",
    "            break\n",
    "            \n",
    "        #plotting single image from each folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reading image from directory\n",
    "for category in CATEGORIES:\n",
    "        label=CATEGORIES.index(category)\n",
    "        path=os.path.join(DATASET,category)\n",
    "        \n",
    "        for img_file in os.listdir(path):\n",
    "            \n",
    "            # 1 indicates read image in RGB scale\n",
    "            # 0 indicates read image in grey scale\n",
    "            \n",
    "            img=cv.imread(os.path.join(path,img_file),1)\n",
    "            img=cv.cvtColor(img,cv.COLOR_BGR2RGB)\n",
    "            dst = cv.fastNlMeansDenoisingColored(img,None,5,10,7,21)\n",
    "            #image convert to smaller pixels 60*60\n",
    "            #print(img.shape)\n",
    "            plt.figure(figsize=(10,8))\n",
    "            plt.subplot(121)\n",
    "            plt.imshow(dst)\n",
    "            plt.subplot(122)\n",
    "            plt.imshow(img)\n",
    "            plt.show()\n",
    "            break\n",
    "            \n",
    "        #plotting single image from each folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make train data\n",
    "train_data=[]\n",
    "\n",
    "for category in CATEGORIES:\n",
    "    \n",
    "        #each cateogry into unique integer\n",
    "        label=CATEGORIES.index(category)\n",
    "        path=os.path.join(DATASET,category)\n",
    "        \n",
    "        for img_file in os.listdir(path):\n",
    "            \n",
    "            img=cv.imread(os.path.join(path,img_file),1)\n",
    "            img=cv.cvtColor(img,cv.COLOR_BGR2RGB)\n",
    "            #dst = cv.fastNlMeansDenoisingColored(img,None,5,10,7,21)\n",
    "            img=cv.resize(img,(60,60))            \n",
    "            train_data.append([img,label])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make test data\n",
    "test_data=[]\n",
    "\n",
    "for category in CATEGORIES:\n",
    "       \n",
    "        #each cateogry into unique integer\n",
    "        label=CATEGORIES.index(category)\n",
    "        path=os.path.join(TEST_DATASET,category)\n",
    "        \n",
    "        for img_file in os.listdir(path):\n",
    "            \n",
    "            img=cv.imread(os.path.join(path,img_file),1)\n",
    "            img=cv.cvtColor(img,cv.COLOR_BGR2RGB)\n",
    "            #dst = cv.fastNlMeansDenoisingColored(img,None,5,10,7,21)\n",
    "            img=cv.resize(img,(60,60))\n",
    "            test_data.append([img,label])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print total data in train and test\n",
    "print(len(train_data))\n",
    "print(len(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#shuffle the dataset fo good result\n",
    "\n",
    "import random\n",
    "\n",
    "random.shuffle(train_data)\n",
    "random.shuffle(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check the data\n",
    "for lbl in train_data[:10]:\n",
    "    print(lbl[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets seprate the feature and target variable\n",
    "train_X=[]\n",
    "train_y=[]\n",
    "\n",
    "for features,label in train_data:\n",
    "    train_X.append(features)\n",
    "    train_y.append(label)\n",
    "\n",
    "len(train_X),len(train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets seprate the feature and target variable\n",
    "test_X=[]\n",
    "test_y=[]\n",
    "\n",
    "for features,label in test_data:\n",
    "    test_X.append(features)\n",
    "    test_y.append(label)\n",
    "\n",
    "len(test_X),len(test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert image array to numpy array\n",
    "#-1 means same size\n",
    "# 40*40 means height and width\n",
    "# 3 for R+G+B\n",
    "train_X=np.array(train_X).reshape(-1,60,60,3)\n",
    "train_X=train_X/255.0\n",
    "train_X.shape\n",
    "\n",
    "#we divide the np array by 255 to close all values to 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert image array to numpy array\n",
    "#-1 means same size\n",
    "# 40*40 means height and width\n",
    "# 3 for R+G+B\n",
    "\n",
    "test_X=np.array(test_X).reshape(-1,60,60,3)\n",
    "test_X=test_X/255.0\n",
    "test_X.shape\n",
    "\n",
    "#we divide the np array by 255 to close all values to 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#count labels\n",
    "\n",
    "sns.countplot(train_y,palette='Set3')\n",
    "#we can see each categroy has equal data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert label into the one hot encode\n",
    "from keras.utils import to_categorical\n",
    "#train y\n",
    "one_hot_train=to_categorical(train_y)\n",
    "one_hot_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_y\n",
    "one_hot_test=to_categorical(test_y)\n",
    "one_hot_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#build the models\n",
    "#import Keras libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D,Dense,Flatten,MaxPooling2D,Dropout,Activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Sequential()\n",
    "\n",
    "model.add(Conv2D(32,(3,3),activation='relu',input_shape=(60,60,3)))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.20))\n",
    "\n",
    "model.add(Conv2D(64,(3,3,activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.20))\n",
    "\n",
    "model.add(Conv2D(128,(3,3),activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.40))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(64,activation='relu'))\n",
    "model.add(Dense(128,activation='relu'))\n",
    "model.add(Dense(64,activation='relu'))\n",
    "          \n",
    "model.add(Dense(4,activation='softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we will choose adam optimizer\n",
    "#we have 4 categories so loss function is categorical_crossentropy\n",
    "#metrics accuracy\n",
    "model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets split the 20% train dataset for validation \n",
    "hist=model.fit(train_X,one_hot_train,epochs=50,batch_size=128,validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model evaluation\n",
    "test_loss,test_acc=model.evaluate(test_X,one_hot_test)\n",
    "test_loss,test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train and validation loss\n",
    "plt.plot(hist.history['loss'])\n",
    "plt.plot(hist.history['val_loss'])\n",
    "plt.title('Model Loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['train','Validation'],loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train and validation accuracy\n",
    "plt.plot(hist.history['acc'])\n",
    "plt.plot(hist.history['val_acc'])\n",
    "plt.title('Model Accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['train','Validation'],loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model prediction\n",
    "\n",
    "y_pred=model.predict_classes(test_X)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "\tprint(\"Actual=%s, Predicted=%s\" % (test_y[i], y_pred[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#accuracy_score\n",
    "from sklearn.metrics import accuracy_score,confusion_matrix\n",
    "accuracy_score(test_y,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(confusion_matrix(test_y,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
